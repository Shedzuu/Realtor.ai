import pandas as pd
import re
import json
import os
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv
import colorama
from colorama import Fore, Style
import textwrap

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º colorama –¥–ª—è —Ü–≤–µ—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
colorama.init()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
load_dotenv()

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω—ã—Ö
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
data_path = os.path.join(BASE_DIR, "data", "apartments.csv")

# –ó–∞–≥—Ä—É–∂–∞–µ–º CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –∫–≤–∞—Ä—Ç–∏—Ä–∞—Ö
try:
    df = pd.read_csv(data_path, index_col=0)
except FileNotFoundError:
    print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {data_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    df = pd.DataFrame()

# –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
api_key = os.environ.get("DEEPSEEK_API_KEY", "sk-74b87290351b47acacfc94680907ed09")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ DeepSeek
client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")

# –§—É–Ω–∫—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
def get_real_estate_details(client_prompt):
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": (
                    "You are a professional realtor. "
                    "Extract the following real estate features from the user's input and make sure values are in Russian and return them as a Python dictionary:\n\n"
                    "{ 'rooms': value, 'adress': value, 'price': value, 'city_region': value, 'floor': value, 'area': value, 'kitchen_studio': value,"
                    " 'apartment_condition': value, 'is_apartment_has_furniture(full or no)': value, 'is_previously_dormitory': value, 'security': value,"
                    " 'furniture_detailed': value, 'facilities': value, 'bathroom': value, 'zhiloi_complex': value, 'house_year': value,"
                    " 'parking': value, 'is_separated_toilet': value, 'toilet_count': value, 'description': value }\n\n"
                    "If any information is missing, replace it with 'No Information'. Ensure the response is a properly formatted JSON string without any markdown formatting."
                )},
                {"role": "user", "content": client_prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {e}")
        return "{}"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è JSON –∏–∑ —Å—Ç—Ä–æ–∫–∏
def extract_json_from_string(response_str):
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ JSON –≤ –±–ª–æ–∫–µ –∫–æ–¥–∞
    json_match = re.search(r'```(?:json)?\n(.*?)\n```', response_str, re.DOTALL)
    
    if json_match:
        json_str = json_match.group(1)
    else:
        # –ï—Å–ª–∏ –±–ª–æ–∫–∞ –∫–æ–¥–∞ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON –Ω–∞–ø—Ä—è–º—É—é
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Ñ–∏–≥—É—Ä–Ω—ã–µ —Å–∫–æ–±–∫–∏
        start = response_str.find('{')
        end = response_str.rfind('}')
        
        if start != -1 and end != -1 and end > start:
            json_str = response_str[start:end+1]
        else:
            return {"error": "No JSON found in response"}
    
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        print(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: {json_str}")
        return {"error": "Invalid JSON format"}

# –ü–æ–¥—Å—á—ë—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
def calculate_similarity_score(df, feature_dict, user_prompt):
    similarity_scores = []
    if df.empty:
        return []
        
    # –ï—Å–ª–∏ DataFrame —Å–æ–¥–µ—Ä–∂–∏—Ç URL –≤ –ø–µ—Ä–≤–æ–º —Å—Ç–æ–ª–±—Ü–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–≥–æ
    data_df = df.iloc[:, 1:] if 'url' in df.columns else df

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –∏—Ö –≤–µ—Å–∞
    key_features = {
        'price': 3.0,      # –¶–µ–Ω–∞ - –æ—á–µ–Ω—å –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
        'rooms': 5.0,      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
        'city_region': 3.0, # –†–∞–π–æ–Ω - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
        'description': 0.5 # –û–ø–∏—Å–∞–Ω–∏–µ - –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
    }
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤–µ—Å –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    default_weight = 1.0
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä –¥–ª—è —É–ª–∏—Ü—ã (–±—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å –∫–∞–∫ —á–∞—Å—Ç—å –∞–¥—Ä–µ—Å–∞)
    street_bonus = 5.0

    # –û—Ç–±–∏—Ä–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∏—Å–∫–ª—é—á–∞–µ–º —Å 'No Information')
    relevant_features = [col for col in data_df.columns if 
                         col in feature_dict and 
                         feature_dict.get(col, "No Information") != "No Information" and 
                         col != "description"]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É–ª–∏—Ü–µ –≤ –∑–∞–ø—Ä–æ—Å–µ
    street_info = None
    if 'adress' in feature_dict and feature_dict['adress'] != "No Information":
        street_info = feature_dict['adress'].lower()
    
    for index, row in data_df.iterrows():
        # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ - –Ω–∞—á–∏–Ω–∞–µ–º —Å 0.2 (20% —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        base_score = 0.2
        feature_similarity = 0
        feature_weights_sum = 0
        total_score = 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
        exact_matches = 0
        key_features_count = 0
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –∫–æ–º–Ω–∞—Ç–∞–º
        if 'rooms' in relevant_features and 'rooms' in row:
            key_features_count += 1
            row_rooms = str(row.get('rooms', "")).strip()
            dict_rooms = str(feature_dict.get('rooms', "")).strip()
            
            if row_rooms and dict_rooms and row_rooms == dict_rooms:
                exact_matches += 1
                # –ë–æ–Ω—É—Å –∑–∞ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–º–Ω–∞—Ç
                base_score += 0.2
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ —Ä–∞–π–æ–Ω—É
        if 'city_region' in relevant_features and 'city_region' in row:
            key_features_count += 1
            row_region = str(row.get('city_region', "")).lower().strip()
            dict_region = str(feature_dict.get('city_region', "")).lower().strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–∂–¥–µ–Ω–∏–µ —Ä–∞–π–æ–Ω–∞
            if row_region and dict_region and (dict_region in row_region or row_region in dict_region):
                exact_matches += 1
                # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–π–æ–Ω–∞
                base_score += 0.2
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ —É–ª–∏—Ü–µ (–≤ –∞–¥—Ä–µ—Å–µ)
        if street_info and 'adress' in row:
            row_address = str(row.get('adress', "")).lower().strip()
            if row_address and street_info in row_address:
                # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –±–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —É–ª–∏—Ü—ã
                base_score += 0.3
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º, 
        # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
        if exact_matches > 0:
            base_score = max(base_score, 0.3 + (exact_matches / key_features_count) * 0.4)
        
        # TF-IDF –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —É—á–µ—Ç–æ–º –≤–µ—Å–æ–≤
        if relevant_features:
            try:
                weighted_similarities = []
                
                for feature in relevant_features:
                    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
                    weight = key_features.get(feature, default_weight)
                    feature_weights_sum += weight
                    
                    # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
                    feature_vectorizer = TfidfVectorizer()
                    row_value = str(row.get(feature, ""))
                    dict_value = str(feature_dict.get(feature, ""))
                    
                    if row_value.strip() and dict_value.strip():
                        tfidf_matrix = feature_vectorizer.fit_transform([dict_value, row_value])
                        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
                        weighted_similarities.append(similarity * weight)
                
                # –°—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–µ–≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                if feature_weights_sum > 0 and weighted_similarities:
                    feature_similarity = sum(weighted_similarities) / feature_weights_sum
                    feature_similarity = feature_similarity * 0.5  # –í–∫–ª–∞–¥ TF-IDF –≤ –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É - 50%
                    
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {str(e)}")

        # TF-IDF –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è (—Å –º–µ–Ω—å—à–∏–º –≤–µ—Å–æ–º)
        description_similarity = 0
        if "description" in data_df.columns:
            try:
                description_text = str(row.get("description", ""))
                if description_text.strip() and user_prompt.strip():
                    desc_vectorizer = TfidfVectorizer()
                    tfidf_desc_matrix = desc_vectorizer.fit_transform([user_prompt, description_text])
                    description_similarity = cosine_similarity(tfidf_desc_matrix[0:1], tfidf_desc_matrix[1:2])[0][0] * 0.3 # –ú–µ–Ω—å—à–∏–π –≤–µ—Å –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ –æ–ø–∏—Å–∞–Ω–∏—è: {str(e)}")

        # –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç - —Å—É–º–º–∞ –±–∞–∑–æ–≤–æ–π –æ—Ü–µ–Ω–∫–∏, TF-IDF –æ—Ü–µ–Ω–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –æ—Ü–µ–Ω–∫–∏ –æ–ø–∏—Å–∞–Ω–∏—è
        total_score = base_score + feature_similarity + description_similarity
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ –¥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-1
        total_score = min(total_score, 1.0)
        
        similarity_scores.append(total_score)

    return similarity_scores

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
def print_detailed_results(df_sorted, client_input, extracted_features, top_n=3):
    terminal_width = os.get_terminal_size().columns
    separator = "=" * terminal_width
    
    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    print(f"\n{Fore.CYAN}{separator}{Style.RESET_ALL}")
    print(f"{Fore.CYAN}üîç –ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:{Style.RESET_ALL}")
    print(f"{Fore.YELLOW}{textwrap.fill(client_input, width=terminal_width)}{Style.RESET_ALL}")
    print(f"{Fore.CYAN}{separator}{Style.RESET_ALL}\n")
    
    # –í—ã–≤–æ–¥–∏–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    print(f"{Fore.CYAN}üìã –ò–ó–í–õ–ï–ß–ï–ù–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:{Style.RESET_ALL}")
    for key, value in extracted_features.items():
        if key != "error" and value != "No Information" and value:
            print(f"{Fore.GREEN}{key}{Style.RESET_ALL}: {value}")
    print(f"\n{Fore.CYAN}{separator}{Style.RESET_ALL}\n")
    
    # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"{Fore.CYAN}üèÜ –¢–û–ü-{top_n} –ü–û–î–•–û–î–Ø–©–ò–• –û–ë–™–ï–ö–¢–û–í:{Style.RESET_ALL}\n")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if len(df_sorted) == 0:
        print(f"{Fore.RED}–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤.{Style.RESET_ALL}")
        return
    
    # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∫–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É
    for i, (idx, row) in enumerate(df_sorted.head(top_n).iterrows()):
        similarity = row.get('similarity_score', 0)
        similarity_percent = int(similarity * 100) if similarity <= 1 else 100
        
        print(f"{Fore.CYAN}#{i+1} - –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {Fore.YELLOW}{similarity_percent}%{Style.RESET_ALL}")
        
        # URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        url = row.get('url', '')
        if url:
            print(f"{Fore.BLUE}üîó –°—Å—ã–ª–∫–∞:{Style.RESET_ALL} {url}")
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"{Fore.BLUE}üè† –ê–¥—Ä–µ—Å:{Style.RESET_ALL} {row.get('adress', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
        print(f"{Fore.BLUE}üí∞ –¶–µ–Ω–∞:{Style.RESET_ALL} {row.get('price', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')} —Ç–≥")
        print(f"{Fore.BLUE}üö™ –ö–æ–º–Ω–∞—Ç:{Style.RESET_ALL} {row.get('rooms', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
        print(f"{Fore.BLUE}üìç –†–∞–π–æ–Ω:{Style.RESET_ALL} {row.get('city_region', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
        print(f"{Fore.BLUE}üìè –ü–ª–æ—â–∞–¥—å:{Style.RESET_ALL} {row.get('area', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
        print(f"{Fore.BLUE}üè¢ –≠—Ç–∞–∂:{Style.RESET_ALL} {row.get('floor', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏
        if 'apartment_condition' in row and row['apartment_condition']:
            print(f"{Fore.BLUE}üîß –°–æ—Å—Ç–æ—è–Ω–∏–µ:{Style.RESET_ALL} {row['apartment_condition']}")
        
        if 'furniture_detailed' in row and row['furniture_detailed']:
            print(f"{Fore.BLUE}üõãÔ∏è –ú–µ–±–µ–ª—å:{Style.RESET_ALL} {row['furniture_detailed']}")
            
        if 'bathroom' in row and row['bathroom']:
            print(f"{Fore.BLUE}üöø –°–∞–Ω—É–∑–µ–ª:{Style.RESET_ALL} {row['bathroom']}")
            
        if 'house_year' in row and row['house_year']:
            print(f"{Fore.BLUE}üìÖ –ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏:{Style.RESET_ALL} {row['house_year']}")
        
        # –û–ø–∏—Å–∞–Ω–∏–µ
        if 'description' in row and row['description']:
            desc = row['description']
            if len(desc) > 200:
                desc = desc[:200] + "..."
            print(f"{Fore.BLUE}üìù –û–ø–∏—Å–∞–Ω–∏–µ:{Style.RESET_ALL} {textwrap.fill(desc, width=terminal_width-10, initial_indent='  ', subsequent_indent='  ')}")
        
        print(f"{Fore.CYAN}{'-' * terminal_width}{Style.RESET_ALL}\n")

# –ü—Ä–∏–º–µ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
client_input = (
    "–ò—â—É 2-–∫–æ–º–Ω–∞—Ç–Ω—É—é –∫–≤–∞—Ä—Ç–∏—Ä—É –≤ –ê–ª–º–∞—Ç—ã, –ê–ª–º–∞–ª–∏–Ω—Å–∫–∏–π —Ä–∞–π–æ–Ω, –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ –ø–æ —É–ª–∏—Ü–µ –ê–π—Ç–µ–∫–∏ –±–∏")

if __name__ == "__main__":
    if not df.empty:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ LLM
        print(f"{Fore.CYAN}–ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è...{Style.RESET_ALL}")
        formatted_response = get_real_estate_details(client_input)
        real_estate_dict = extract_json_from_string(formatted_response)
        
        if "error" not in real_estate_dict:
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
            print(f"{Fore.CYAN}–ü–æ–∏—Å–∫ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤...{Style.RESET_ALL}")
            df["similarity_score"] = calculate_similarity_score(df, real_estate_dict, client_input)
            df_sorted = df.sort_values("similarity_score", ascending=False)
            
            # –í—ã–≤–æ–¥ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
            print_detailed_results(df_sorted, client_input, real_estate_dict)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            results_path = os.path.join(BASE_DIR, "data", "search_results.csv")
            df_sorted.to_csv(results_path)
            print(f"{Fore.CYAN}–ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_path}{Style.RESET_ALL}")
        else:
            print(f"{Fore.RED}–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM: {real_estate_dict['error']}{Style.RESET_ALL}")
    else:
        print(f"{Fore.RED}–î–∞–Ω–Ω—ã–µ –æ –∫–≤–∞—Ä—Ç–∏—Ä–∞—Ö –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É.{Style.RESET_ALL}")
